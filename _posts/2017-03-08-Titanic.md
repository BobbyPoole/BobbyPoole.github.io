The Titanic. Over a hundred years ago it was considered the gold standard of luxury and transportation. Even though the ships demise ultimately tarnished it's legacy as the greatest ship ever for it's time, three things came from this. First, boats had to have better safety features to accommodate for an emergency like more lifeboats. Second, a major plot line for one of the best films of the past 25 years. And third, the data set for my next project. The goal with this data was to use information about the passengers on the Titanic like age, which class they were staying in, and gender among other elements in order to predict which people were saved and which drowned.

Data and Assumptions:
For this data set, I used the Titanic data set from Kaggle. I started with the name, gender, age, class on the ship, number of siblings/spouses aboard, number of parents/children aboard, the ticket stub information, where they embarked from, if they had a cabin and if they survived. I ultimately decided to not include cabin in the final model since such a low percent of people had a cabin. I also chose not to include the name and the ticket stub since having a certain name wouldn't necessarily have an impact on whether or not they were saved (although that does not include titles that the person may have which I will elaborate on a little later). Finally, I did not include the ticket number since it was challenging given the limited amount of time that I had to be able to properly go into detail about what could be important in determining where an individual was on the ship based on the stub (for instance if a stub had a certain letter or number, the model could determine that that area had a higher rate of mortality than those that did not contain those elements) and how that may have contributed to their death or potentially saved them. Ultimately, using those remaining elements, I will construct several types of models including a decision tree, random forest, KNN and logistic regression in order to predict which passengers perished on the Titanic.

Data Cleaning:
As a start looking through my data set I took a peak as to the types of items I started with.
![Image Name](../images/Titanic.Data.jpg)

I want to initially start by making sure that each element is represented by a number in order to make the model functional. I start with the name since this is the most complicated one to change.

I look at the first ten and see that all of the names are different, but each person has a title which comes directly after the comma. This means I can split on the comma ask for the first element after the comma and then count all of the titles that exist in the data.

I chose to group all of these titles into six groups which include Mr., Miss., Mrs., Master, Prof(Professional) and Roy(royalty) in order to encompass the six major groups these titles represented which were men, single women, married women, children, individuals with titles in their fields of work like doctor or reverend and individuals with royalty tiles like Countess or Lady. By doing this I add a little depth that goes beyond the given data by adding a little information like prestige which may go beyond just the class they resided in and the ambiguity of whether they were married or had a sibling but doesn't specify which of those two is the element that actually applies for that person. In doing so though, I made assumptions about which groups some of these individuals belonged in. For instance one of the individuals had a title of Mlle. (Mademoiselle) which I grouped with the Miss. because she was 24 years old and was not married but could have been and has since divorced. One of the most fascinating finds was seeing that of all the doctors in this group one was a woman named Dr. Alice Farnham Leader which is amazing to consider this was over 100 years ago and female doctors were likely few and far between.


Next, I dealt with where each person embarked on. Most had information but two individuals did not. Using the internet I looked up the two individuals who had no information on where they embarked and ended up finding out the two people were  Mrs. George Nelson Stone (Martha Evelyn) and her maid Amelie Icard. I imputed the results so I could include both of them in the model.

The age was probably one of the trickier portions because close to 20% of the almost 900 people did not have ages. I opted for those who did not have ages to use the average of all the other people who fit that category. For instance if a woman was in first class and had the title Miss. then she was given an age of 29.74 based on the average of all of the known women who had the title of Miss and were in first class. Again this is fairly presumptive on my part but I felt that having a number that was relatively representative was far better than losing 20% of my data.

Finally I created a binary feature for the sex, where they embarked, class and the title in order to use it properly for the KNN, random forest and decision tree models. For the logistic regression, I needed to drop 1 variable for all the aforementioned features (except for sex since there was only 1 feature utilizing that).

EDA
Before creating my model I wanted to take some time and see how my data was distributed. It was interesting to see how men far and away outnumbered the women. Another interesting part was that here a lot of men in their early thirties where as a significant number of women were those in their mid to late teens and their mid 20s.

An even more interesting piece was how little most people paid.  Most people paid a pound to board with only a small number of people paying more than 100 pounds.

Finally, I looked at which ages had the highest mortality rates from my data set. More than half of the people over the age of 55 died as well as those aged 20-30. Conversely, a high percent of children and teenagers were among those that survived. While I didn't look specifically at kids for the chart (though data shows women survived at a higher rate) the use of the term women and children first when having passengers board onto rafts to attempt to move to safety was highly accurate.

Models:
I did four different types of models for this dataset in order to see which had the best outcomes. The goal was to beat the minimum threshold of 62% which was the number of individuals in the data set who died.
For the logistic regression model, I created a ROC curve in order to  create a physical representation of how accurate the model was. Ultimately, it had a 82.37% accuracy.

For my KNN model I used the three nearest neighbors and ended up with a 72.2% accuracy. Then I used gridsearch to maximize my result which ultimately gave me a score of 84.75%.

Finally, I did both a decision tree and a random forest where I scored 74.7% with a variation of 1.7% and 80% with a variation of .9% respectively.

Conclusion:

This was probably one of the most successful models to date. Though the data set given did limit some of the ingenuity that could be brought in for other types of features, the accuracy was high relative to the minimum threshold of 62%. One of the pieces that I needed to take a lot of risk was guessing the age for the passengers which on face value may not be the craziest idea in the world but can if used improperly be problematic and ruin a potentially good model. Additionally, it's also important to look at another angle in how to approach the problem. Adding a status title adds a bit of depth that class wouldn't have covered otherwise. Making little additions like that provide some extra depth to figuring out the best way for a model to function.

The Titanic. Over a hundred years ago it was considered the gold standard of luxury and transportation. Even though the ships demise ultimately tarnished it's legacy as the greatest ship ever for it's time, three positive things came from this. First, boats had to have better safety features to accommodate for an emergency like more lifeboats. Second, a major plot line for one of the best films of the past 25 years. And third, the data set for my next project. The goal with this data was to use information about the passengers on the Titanic like age, which class they were staying in, and gender among other elements, to predict which people were saved and which drowned.

Data and Assumptions:
For this data set, I used the Titanic data set from Kaggle. I started with the name, gender, age, class on the ship, number of siblings/spouses aboard, number of parents/children aboard, the ticket stub information, where they embarked from, if they had a cabin and if they survived. I ultimately decided to not include cabin in the final model since such a low percent of people had a cabin, it didn't make sense to include it. I also chose not to include the name and the ticket stub since having a certain name wouldn't necessarily have an impact on whether or not they were saved (although that does not include titles that the person may have which I will elaborate on a little later). Finally I did not include the ticket number since it was challenging given the limited amount of time that I had to be able to properly go into detail about what could be important in determining where an individual was on the ship based on the stub (for instance if a stub had a certain number letter or number the model could determine that that area had a a higher rate of mortality than those that did not contain those elements) and how that may have contributed to their death or potentially saved them. Ultimately, using those remaining elements, I will construct several types of models including a decision tree, random forest, KNN and logistic regression in order to predict which passengers perished on the Titanic.

Data Cleaning:
As a start looking through my data set I took a peak as to the types of items I started with.
![Image Name](../images/Titanic.Data.jpg)

I want to initially start by making sure that each element is represented by a number in order to make the model functional. I start with the name since this is the most complicated one to change.

I look at the first ten and see that all of the names are different, but each person has a title which comes directly after the comma. This means I can split on the comma ask for the first element after the comma and then count all of the titles that exist in the data.

I chose to group all of these titles into six groups which include Mr., Miss., Mrs., Master, Prof(Professional) and Roy(royalty) in order to encompass the six major groups these titles represented which were men, single women, married women, children, individuals with titles in their fields of work like doctor or reverend and individuals with royalty tiles like Countess or Lady. By doing this I add a little depth that goes beyond the given information by adding a little information like prestige which may go beyond just the class they resided in and the ambiguity of whether they were married or had a sibling but doesn't specify which of those two is the element that actually applies for that person. In doing so though, I made assumptions about which groups some of these individuals belonged in. For instance one of the individuals had a title of Mlle. (Mademoiselle) which I grouped with the Miss. because she was 24 years old and was not married but could very well have been previously and had since divorced. One of the most fascinating finds was seeing that of all the doctors in this group one was a woman named Dr. Alice Farnham Leader which is amazing to consider this was over 100 years ago and female doctors were likely few and far between.


Next, I dealt with where each person embarked on. Most had information but two individuals did not. Using the internet I looked up the two individuals who there was no place and two individuals ended up being Mrs. George Nelson Stone ( Martha Evelyn) and her maid Amelie Icard. I imputed the results so I could include both of them in the model.

The age was probably one of the trickier portions because close to 20% of the almost 900 people did not have ages. I opted for those who did not have ages you use the average of all the other people who fit that category. For instance if a woman was in first class had the title Miss. then she was given an age of 29.74. Again this is fairly presumptive on my part but I felt that having a number that was relatively representative was far better than losing 20% of my data.

Finally I created a binary feature for the sex, where they embarked, class and the title in order to use it properly for KNN, random forest and my decision tree models. For the logistic regression, I needed to drop 1 variable for all the aforementioned features (except for sex since there was only 1 feature utilizing that).

EDA
Before creating my model I wanted to take some time and see how my data was distributed. It was incredible to me how men far and away outnumbered the women (though it is 1912 so I shouldn't be as surprised as I am). The less surprising part was there a lot of men in their early thirties where as the biggest jumps for women were those in their mid to late teens and their mid 20s.

Another interesting piece was how little most people paid.  Most people paid a few dollars to board with only a small number of people paying more than 100 Pound Sterling.

Finally, I looked at which ages had the highest mortality rates from my data set. More than half of the people over the age of died as well as those aged 20-30. Conversely, a high percent of children and teenagers were among those that survived. While I didn't look specifically at kids for the chart (though data shows women survived at a higher rate) the use of the term women and children first when having passengers board onto rafts to attempt to move to safety was highly accurate.

Models:
For the logistic regression model, I created a ROC curve in order to  create a physical representation of how accurate the model was. Ultimately, it had a 82.37% accuracy. 

For my KNN model I used the three nearest neighbors and ended up with a 72.2% accuracy. Then I used gridsearch to maximize my result which ultimately gave me a score of 84.75%.

Finally, I did both a decision tree and a random forest where I scored 74.7% with a variation of 1.7% and 80% with a variation of .9% respectively.
